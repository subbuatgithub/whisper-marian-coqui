{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebf80567",
   "metadata": {},
   "source": [
    "# ðŸŽ¤ Whisper + MarianMT + Coqui TTS Pipeline on Paperspace\n",
    "\n",
    "This notebook demonstrates a full speech translation pipeline:\n",
    "1. Audio input using Whisper\n",
    "2. Translation using MarianMT (HuggingFace)\n",
    "3. Speech synthesis using Coqui TTS\n",
    "\n",
    "âœ… Offline, GPU-supported, open-source, and works on Paperspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc11e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/openai/whisper.git\n",
    "!pip install transformers sentencepiece\n",
    "!pip install TTS\n",
    "!pip install gradio torchaudio pydub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2547edc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import torch\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "from TTS.api import TTS\n",
    "import gradio as gr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc26d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Whisper model\n",
    "whisper_model = whisper.load_model(\"base\")  # or 'small', 'medium', 'large'\n",
    "\n",
    "# Load MarianMT model and tokenizer (English to Hindi example)\n",
    "translation_model_name = \"Helsinki-NLP/opus-mt-en-hi\"\n",
    "translator_tokenizer = MarianTokenizer.from_pretrained(translation_model_name)\n",
    "translator_model = MarianMTModel.from_pretrained(translation_model_name)\n",
    "\n",
    "# Load Coqui TTS model\n",
    "tts = TTS(model_name=\"tts_models/en/ljspeech/tacotron2-DDC\", progress_bar=False, gpu=torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023706ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_text(text, model, tokenizer):\n",
    "    tokens = tokenizer(text, return_tensors=\"pt\", padding=True)\n",
    "    translated = model.generate(**tokens)\n",
    "    return tokenizer.decode(translated[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1a9220",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(audio_path):\n",
    "    # 1. Transcribe\n",
    "    result = whisper_model.transcribe(audio_path)\n",
    "    english_text = result['text']\n",
    "\n",
    "    # 2. Translate\n",
    "    translated_text = translate_text(english_text, translator_model, translator_tokenizer)\n",
    "\n",
    "    # 3. TTS\n",
    "    output_path = \"output.wav\"\n",
    "    tts.tts_to_file(text=translated_text, file_path=output_path)\n",
    "\n",
    "    return english_text, translated_text, output_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae70f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.Interface(\n",
    "    fn=pipeline,\n",
    "    inputs=gr.Audio(source=\"upload\", type=\"filepath\"),\n",
    "    outputs=[\"text\", \"text\", gr.Audio(type=\"filepath\")],\n",
    "    title=\"ðŸŽ¤ Whisper + MarianMT + Coqui TTS\",\n",
    "    description=\"Upload audio, get translated speech back!\"\n",
    ").launch()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}